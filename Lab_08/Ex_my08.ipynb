{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "wjzcO9SETD5Z"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout, Activation, LSTM\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "font = {'weight' : 'bold',\n",
        "        'size'   : 12}\n",
        "\n",
        "matplotlib.rc('font', **font)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O kafka_Metamorphosis.txt https://www.gutenberg.org/files/5200/5200-0.txt"
      ],
      "metadata": {
        "id": "DvefmF-ZJw-z",
        "outputId": "7d374d99-59a9-4b2e-b3e1-782120edad1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-06 07:05:51--  https://www.gutenberg.org/files/5200/5200-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142017 (139K) [text/plain]\n",
            "Saving to: ‘kafka_Metamorphosis.txt’\n",
            "\n",
            "kafka_Metamorphosis 100%[===================>] 138.69K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-04-06 07:05:51 (1.27 MB/s) - ‘kafka_Metamorphosis.txt’ saved [142017/142017]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = open('kafka_Metamorphosis.txt', 'r').read().lower()\n",
        "print('text length: ', len(text))"
      ],
      "metadata": {
        "id": "v3cwb2zqKfuz",
        "outputId": "60b85531-2f51-4673-c1c7-83d01a098f0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text length:  138408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[10000:11000])"
      ],
      "metadata": {
        "id": "tDYK0-oLLoyV",
        "outputId": "ce4531d7-a31a-470c-997d-5bf4d17b8221",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " too hard to move; it\n",
            "went so slowly; and finally, almost in a frenzy, when he carelessly\n",
            "shoved himself forwards with all the force he could gather, he chose\n",
            "the wrong direction, hit hard against the lower bedpost, and learned\n",
            "from the burning pain he felt that the lower part of his body might\n",
            "well, at present, be the most sensitive.\n",
            "\n",
            "so then he tried to get the top part of his body out of the bed first,\n",
            "carefully turning his head to the side. this he managed quite easily,\n",
            "and despite its breadth and its weight, the bulk of his body eventually\n",
            "followed slowly in the direction of the head. but when he had at last\n",
            "got his head out of the bed and into the fresh air it occurred to him\n",
            "that if he let himself fall it would be a miracle if his head were not\n",
            "injured, so he became afraid to carry on pushing himself forward the\n",
            "same way. and he could not knock himself out now at any price; better\n",
            "to stay in bed than lose consciousness.\n",
            "\n",
            "it took just as much effort to get back to where he had be\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars: ', len(chars))"
      ],
      "metadata": {
        "id": "Ui1cUMTgLu-c",
        "outputId": "e56b9804-7d0c-41ca-8934-e10f42269820",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total chars:  62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "metadata": {
        "id": "X_Exko_MNFNQ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "  sentences.append(text[i: i + maxlen])\n",
        "  next_chars.append(text[i + maxlen: i + maxlen + 1])\n",
        "\n",
        "print('nb sentences: ', len(sentences))"
      ],
      "metadata": {
        "id": "KKAXNAoFNjsI",
        "outputId": "f9a54bbb-c30d-4f8f-9051-5c5bb9156ecd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nb sentences:  46123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sentences[:3])\n",
        "print(next_chars[:3])"
      ],
      "metadata": {
        "id": "NjZq80YFN_fp",
        "outputId": "23bfa00a-1621-477a-8a75-460699bfc505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\ufeffthe project gutenberg ebook of metamorp', 'e project gutenberg ebook of metamorphos', 'roject gutenberg ebook of metamorphosis,']\n",
            "['h', 'i', ' ']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "  for t, char in enumerate(sentence):\n",
        "    x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1"
      ],
      "metadata": {
        "id": "lZQCauGLObWA",
        "outputId": "5049c5ba-b0fc-406a-95a7-cf4bcf3989a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-8b86d899b220>:1: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
            "<ipython-input-30-8b86d899b220>:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[:3])\n",
        "print(y[:3])"
      ],
      "metadata": {
        "id": "q3yOOO8iPdj7",
        "outputId": "e2c2d3ef-a477-4ef0-e9d2-3e7f75fc176c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[False False False ... False False  True]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False  True False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]\n",
            "\n",
            " [[False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  ...\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]\n",
            "  [False False False ... False False False]]]\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False  True False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(254, input_shape = (maxlen, len(chars))))\n",
        "model.add(Dense(10*len(chars)))\n",
        "model.add(Dense(len(chars)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "v8NPvfqcPqor"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.01))"
      ],
      "metadata": {
        "id": "oek4JUJDQlou",
        "outputId": "45662ef9-46b0-41a2-9057-44f9ec0ae3b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size = 128, epochs = 10)"
      ],
      "metadata": {
        "id": "rWN2sirRRnJ3",
        "outputId": "1aac1566-ff33-43aa-cabe-4bd3f3c980a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "361/361 [==============================] - 9s 13ms/step - loss: 4.1306\n",
            "Epoch 2/10\n",
            "361/361 [==============================] - 4s 10ms/step - loss: 1.9681\n",
            "Epoch 3/10\n",
            "361/361 [==============================] - 4s 11ms/step - loss: 1.7280\n",
            "Epoch 4/10\n",
            "361/361 [==============================] - 4s 11ms/step - loss: 1.5686\n",
            "Epoch 5/10\n",
            "361/361 [==============================] - 4s 10ms/step - loss: 1.4530\n",
            "Epoch 6/10\n",
            "361/361 [==============================] - 3s 9ms/step - loss: 1.3474\n",
            "Epoch 7/10\n",
            "361/361 [==============================] - 3s 9ms/step - loss: 1.2566\n",
            "Epoch 8/10\n",
            "361/361 [==============================] - 4s 11ms/step - loss: 1.1687\n",
            "Epoch 9/10\n",
            "361/361 [==============================] - 3s 9ms/step - loss: 1.0845\n",
            "Epoch 10/10\n",
            "361/361 [==============================] - 3s 9ms/step - loss: 1.0113\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f666277da00>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature = 1.0):\n",
        "  preds = np.asarray(preds).astype('float64')\n",
        "  preds = np.log(preds) / temperature\n",
        "  exp_preds = np.exp(preds)\n",
        "  preds = exp_preds / np.sum(exp_preds)\n",
        "  probas = np.random.multinomial(i, preds, 1)\n",
        "  return np.argmax(probas)\n",
        "\n",
        "def generate_text(sentence, length, diversity):\n",
        "  generated = ''\n",
        "  generated += sentence\n",
        "  for i in range(length):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "      x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    pred = model.predict(x_pred, verbose = 0)[0]\n",
        "    next_index = sample(pred, diversity)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "  \n",
        "  return generated"
      ],
      "metadata": {
        "id": "87ztlke3R1ve"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" the first thing he wanted to create is \"\n",
        "len(text)"
      ],
      "metadata": {
        "id": "P6w3HXHcaSE3",
        "outputId": "945271b9-a543-401d-b75c-30b76108bd18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = text[0: maxlen]\n",
        "\n",
        "print(generate_text(sentence, 30, 0.2))"
      ],
      "metadata": {
        "id": "2JFA-SPKZXhF",
        "outputId": "d1f360eb-49c6-44dd-aa29-ad8362d9ff0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " the first thing he wanted to create is if if we would be seen in this\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}