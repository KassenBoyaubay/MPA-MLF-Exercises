{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr883cxr2w1g"
      },
      "source": [
        "# MPA-MLF, Lab 5 - Feedforward Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWKpUeA1J8Sv"
      },
      "source": [
        "These exercises are focused on dealing with neural networks. It is strongly recommended to use google collab for these pc labs. Why? Google collab offers a free GPU capacity to train machine learning models. Training NN on GPU can drastically speed up the training process. You can turn on the GPU accelerator in: Runtime -> Change runtime type -> GPU, "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejOYhsl_KlHt"
      },
      "source": [
        "## Exercise 1 - XOR problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLfjemjJKuPV"
      },
      "source": [
        "During the last lecture, we saw that the single perceptron model with a step function could be used only for solving linearly-separable classification problems. Because of that, a single perceptron can not be trained to be able to behave like an XOR gate. To approximate the XOR gate using a neural network, we need to use the following structure:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7hCklzwNm_9"
      },
      "source": [
        "![nn.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyWI7oiCQsPT"
      },
      "source": [
        "The above structure contains three layers: two neurons in the input layer (blue), two in the hidden layer and one in the output layer (yellow). The input layer represents the identity functions (the outputs are equal to the inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBGB2Zq4CN0z"
      },
      "source": [
        "We will use *Keras* API to build and train our neural network. Keras is an open-source neural network library written in Python. It is designed to enable fast experimentation with deep neural networks and provides a high-level API for building and training neural networks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiMMyX7B2zUw"
      },
      "source": [
        "### 0. First import libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FzC8HPME2pgP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnLbt_-U2_4Y"
      },
      "source": [
        "### 1. prepare data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kwB40qi5cQr"
      },
      "source": [
        "In this part, the task would be to prepade our dataset, basically it is the logic table for *XOR* function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gWLETf7k2wiY"
      },
      "outputs": [],
      "source": [
        "X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "y = [0, 1, 1, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ5ZwSDU3Qho"
      },
      "source": [
        "### 2. Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Otl0iDM5lHm"
      },
      "source": [
        "To create a model of NN that is in the picture above, run the following cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RpAah84r2vyw"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=2, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoBvH8UQDM95"
      },
      "source": [
        "**Sequential** is a model type used in Keras for building feedforward neural networks. It is called \"sequential\" because the layers are stacked sequentially on top of each other, and the output of one layer is passed as input to the next layer.\n",
        "\n",
        "To create a sequential model, instantiate a Sequential object and then add layers to it using the **add()** method. There are many layers that Keras offers. We will use *Dense layer*\n",
        "\n",
        "**Dense layer** represents a fully connected layer, which means that every neuron in the layer is connected to every neuron in the previous layer. In each layer, we will specify an activation function and the number of neurons that layer contains. The input layer is not defined as a dense layer, but instead of that, we will specify the *input_dim* parameter in the layer that follows the input layer. *input_dim* parameter specifies the number of neurons in the input layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtNu4JiE3XVw"
      },
      "source": [
        "### 3. Compile the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHk2-s3V5_Hb"
      },
      "source": [
        "To compile yor model run:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "GCKtEOAf3awX"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pf4-t6PGDEv"
      },
      "source": [
        "**keras.complile()** is used to configure the learning process before training the model. \n",
        "We need to specify 3 parameters:\n",
        "- *loss*, *optimizer* and *metrics*\n",
        "\n",
        "- as our loss function (error function/objective function), we will choose *binary_crossentropy* - loss function often used for binary classification\n",
        "\n",
        "- *optimizer* is optimization algorithm used for optimizing weights in our training process, we will choose *stochastic gradient descent* \n",
        "\n",
        "- *metrics* is metric user for model evaluation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY0oJ_g13d7o"
      },
      "source": [
        "### 4. Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dX_p6mn4aoX"
      },
      "source": [
        "In the lecture, we talked about training the Multi-layer perceptron. The training process consists of the following steps:\n",
        "\n",
        "1. Weight initialization\n",
        "2. Forward Propagation\n",
        "3. Compute Loss\n",
        "4. Backpropagation\n",
        "5. Update Weights\n",
        "6. Repeat 2->6 until maximum epochs are reached\n",
        "\n",
        "When training a machine learning model, the training data is usually divided into batches (parts), and the model updates its weights after processing each batch. The batch size determines how many training examples are included in each batch. \n",
        "\n",
        "For example, we have 10,000 training examples and a batch size of 100. In this case, the training data would be divided into 100 batches of 100 examples each. During training, the model would process each batch, calculate the loss or error, and update its weights based on the average of the errors in that batch. In other words, if we batch equal to 1. we will update the weights 10 000 times. If we have batch size == 100, we will update the weights only 100 times "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhlzz2hr0n5Y"
      },
      "source": [
        "To train your model, run the following line of the code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "sE7eNdJi3gbX"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X, y, epochs=1000, batch_size=1, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJNcrzuu02Kn"
      },
      "source": [
        "the method **.fit()**, is used to train the model. We can see that it takes several input parameters:\n",
        " - *X* - input data\n",
        " - *y* - label for the input data\n",
        " - *epochs* number of training epochs (iterations)\n",
        " - *batch_size* - number of samples in each batch\n",
        " - *verbose* - set verbose parameter to see the progress of loss and metrics during the training epochs\n",
        "\n",
        "These are not the only parameters the .fit() method can take. Check official documentation: https://keras.io/api/models/model_training_apis/\n",
        "\n",
        "We will set the output of our .fit() function to variable *history*, where the loss and other metrics defined above in the .compile() function during the training are saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1M4VvU83jXY"
      },
      "source": [
        "### 5. Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdJl6X-61gL4"
      },
      "source": [
        "Out training process is finished. To evaluate the performance of our model on test data, tun the following cell of the code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbM0bLm83iiQ",
        "outputId": "5788e72f-4a64-40ce-b7a1-4d711adf34f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f1507651d30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.00\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X, y, verbose=0)\n",
        "print('Accuracy: {:.2f}'.format(accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYloVKFcUcYP"
      },
      "source": [
        "### 6. Model predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEO2iQHnUjDo",
        "outputId": "50df7294-1b5e-4900-ae42-23213a8f01b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n",
            "Data sample is [0, 0], prediction from model [[0.00050844]], ground_truth 0\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Data sample is [0, 1], prediction from model [[0.9980215]], ground_truth 1\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Data sample is [1, 0], prediction from model [[0.9973456]], ground_truth 1\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Data sample is [1, 1], prediction from model [[0.00535123]], ground_truth 0\n"
          ]
        }
      ],
      "source": [
        "for id_x, data_sample in enumerate(X):\n",
        "  prediction = model.predict([data_sample])\n",
        "  print(f\"Data sample is {data_sample}, prediction from model {prediction}, ground_truth {y[id_x]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znRHpDEbABvg"
      },
      "source": [
        "### 7. Display loss function during the training process and acuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "zmFOaJHA41Tb",
        "outputId": "83f052d4-23ba-4245-86aa-052cf0c0aee4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('n epochs')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YK40q-xmHvIr"
      },
      "source": [
        "### TASK:\n",
        "\n",
        "In this part of the exercise, the task would be to play around with the code above to see the influence of hyperparameters.\n",
        "\n",
        "As we know from the lecture, neural networks contain two types of parameters:\n",
        "  1. **Learnable parameters** - *weights* and *biases*. these parameters are adjusted in the training process.  \n",
        "  2. **Non-learnable parameters (hyperparameters)** - learning_rate, number_of_neurons, number_of_layers, number_of_epochs, type of activation functions in the neurons.., basically any user-defined setting is considered to be hyperparameter\n",
        "\n",
        "\n",
        "Change the following parameters: \n",
        "- number of epochs\n",
        "- learning_rate\n",
        "- activation functions in layers, \n",
        "- batch_size,\n",
        "- verbose,\n",
        "- number of neurons in the hidden layer\n",
        "\n",
        "Moreover, see the influence on the training process and results.\n",
        "\n",
        "**Note: Every time we change some hyper-parameters, do not forget to compile the model, to initialize the learnable parameters again**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbMYYFtl8lhd"
      },
      "source": [
        "## Exercise 2 - Congressional Voting Data\n",
        "\n",
        "In the attached dataset, results from congressional voting can be found. Your task is to train a model that can recognize that the politician is *republican* or *democrat* based on voting results. We would follow the general machine learning steps that were described in the lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "VCvGPSYX8pbf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSoCAe_gAAP5"
      },
      "source": [
        "### 1. Loading dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm8Kj3sJiLAx"
      },
      "source": [
        "**First mount your google drive to google colab file.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/KassenBoyaubay/MPA-MLF-Exercises/main/Lab_05/voting_complete.csv"
      ],
      "metadata": {
        "id": "eQS6UuBLTE37",
        "outputId": "0dcf57fc-b0ed-4027-b0ed-c8074ebe934e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-09 07:35:32--  https://raw.githubusercontent.com/KassenBoyaubay/MPA-MLF-Exercises/main/Lab_05/voting_complete.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20166 (20K) [text/plain]\n",
            "Saving to: voting_complete.csv\n",
            "\n",
            "\rvoting_complete.csv   0%[                    ]       0  --.-KB/s               \rvoting_complete.csv 100%[===================>]  19.69K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-03-09 07:35:33 (26.1 MB/s) - voting_complete.csv saved [20166/20166]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ktvZOBUyTH-p",
        "outputId": "4ef80d39-8dcc-4e75-b985-698360af3342",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "AqSVkJc8_f4R"
      },
      "outputs": [],
      "source": [
        "path_to_dataset = 'voting_complete.csv' # change the PATH\n",
        "pd_dataset = pd.read_csv(path_to_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "ZHxyq2C5_vJh",
        "outputId": "8e1a0d01-c992-4f51-a3f8-64e5b93e9d37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Unnamed: 0  Class Name handicapped-infants water-project-cost-sharing  \\\n",
              "0             0  republican                   n                          y   \n",
              "1             1  republican                   n                          y   \n",
              "2             2    democrat                   ?                          y   \n",
              "3             3    democrat                   n                          y   \n",
              "4             4    democrat                   y                          y   \n",
              "..          ...         ...                 ...                        ...   \n",
              "430         430  republican                   n                          n   \n",
              "431         431    democrat                   n                          n   \n",
              "432         432  republican                   n                          ?   \n",
              "433         433  republican                   n                          n   \n",
              "434         434  republican                   n                          y   \n",
              "\n",
              "    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n",
              "0                                   n                    y               y   \n",
              "1                                   n                    y               y   \n",
              "2                                   y                    ?               y   \n",
              "3                                   y                    n               ?   \n",
              "4                                   y                    n               y   \n",
              "..                                ...                  ...             ...   \n",
              "430                                 y                    y               y   \n",
              "431                                 y                    n               n   \n",
              "432                                 n                    y               y   \n",
              "433                                 n                    y               y   \n",
              "434                                 n                    y               y   \n",
              "\n",
              "    religious-groups-in-schools anti-satellite-test-ban  \\\n",
              "0                             y                       n   \n",
              "1                             y                       n   \n",
              "2                             y                       n   \n",
              "3                             y                       n   \n",
              "4                             y                       n   \n",
              "..                          ...                     ...   \n",
              "430                           y                       n   \n",
              "431                           n                       y   \n",
              "432                           y                       n   \n",
              "433                           y                       ?   \n",
              "434                           y                       n   \n",
              "\n",
              "    aid-to-nicaraguan-contras mx-missile immigration  \\\n",
              "0                           n          n           y   \n",
              "1                           n          n           n   \n",
              "2                           n          n           n   \n",
              "3                           n          n           n   \n",
              "4                           n          n           n   \n",
              "..                        ...        ...         ...   \n",
              "430                         n          y           y   \n",
              "431                         y          y           y   \n",
              "432                         n          n           n   \n",
              "433                         ?          ?           ?   \n",
              "434                         n          n           y   \n",
              "\n",
              "    synfuels-corporation-cutback education-spending superfund-right-to-sue  \\\n",
              "0                              ?                  y                      y   \n",
              "1                              n                  y                      y   \n",
              "2                              y                  n                      y   \n",
              "3                              y                  n                      y   \n",
              "4                              y                  ?                      y   \n",
              "..                           ...                ...                    ...   \n",
              "430                            n                  y                      y   \n",
              "431                            n                  n                      n   \n",
              "432                            y                  y                      y   \n",
              "433                            n                  y                      y   \n",
              "434                            n                  y                      y   \n",
              "\n",
              "    crime duty-free-exports export-administration-act-south-africa  \n",
              "0       y                 n                                      y  \n",
              "1       y                 n                                      ?  \n",
              "2       y                 n                                      n  \n",
              "3       n                 n                                      y  \n",
              "4       y                 y                                      y  \n",
              "..    ...               ...                                    ...  \n",
              "430     y                 n                                      y  \n",
              "431     n                 n                                      y  \n",
              "432     y                 n                                      y  \n",
              "433     y                 n                                      y  \n",
              "434     y                 ?                                      n  \n",
              "\n",
              "[435 rows x 18 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08d77516-f588-48e1-9b61-78d24ebca7fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Class Name</th>\n",
              "      <th>handicapped-infants</th>\n",
              "      <th>water-project-cost-sharing</th>\n",
              "      <th>adoption-of-the-budget-resolution</th>\n",
              "      <th>physician-fee-freeze</th>\n",
              "      <th>el-salvador-aid</th>\n",
              "      <th>religious-groups-in-schools</th>\n",
              "      <th>anti-satellite-test-ban</th>\n",
              "      <th>aid-to-nicaraguan-contras</th>\n",
              "      <th>mx-missile</th>\n",
              "      <th>immigration</th>\n",
              "      <th>synfuels-corporation-cutback</th>\n",
              "      <th>education-spending</th>\n",
              "      <th>superfund-right-to-sue</th>\n",
              "      <th>crime</th>\n",
              "      <th>duty-free-exports</th>\n",
              "      <th>export-administration-act-south-africa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>democrat</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>democrat</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>democrat</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>430</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>431</td>\n",
              "      <td>democrat</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>432</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>433</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>434</td>\n",
              "      <td>republican</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>435 rows  18 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08d77516-f588-48e1-9b61-78d24ebca7fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-08d77516-f588-48e1-9b61-78d24ebca7fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-08d77516-f588-48e1-9b61-78d24ebca7fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "pd_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrHZUFV-AEYh"
      },
      "source": [
        "### 2. Train/Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Odr83IAcYP"
      },
      "source": [
        "Fistlty we need to split our dataset into train and test. We will use 80% of dataset as our trainset and 20% od dataset as our testset. You can use functions included in *keras*, *scikit-learn*, or you can write your own:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "24w7ksCcAddN"
      },
      "outputs": [],
      "source": [
        "# define a function for train and test split\n",
        "\n",
        "def train_test_split(pd_data: pd.DataFrame, test_ratio: float = 0.2) -> tuple:\n",
        "    pd_dataset = pd_data.copy()\n",
        "    pd_dataset = pd_dataset[pd_dataset.columns[1:]]\n",
        "    index = np.arange(len(pd_dataset))\n",
        "    index = np.random.permutation(index)\n",
        "    train_ammount = int(len(index)*test_ratio)\n",
        "    train_ids = index[train_ammount:]\n",
        "    test_ids = index[:train_ammount]\n",
        "    \n",
        "    train_dataset = pd_dataset[pd_dataset.index.isin(train_ids)].reset_index()\n",
        "    test_dataset = pd_dataset[pd_dataset.index.isin(test_ids)].reset_index()\n",
        "    \n",
        "    train_dataset = train_dataset[train_dataset.columns[1:]]\n",
        "    test_dataset = test_dataset[test_dataset.columns[1:]]\n",
        "\n",
        "    return train_dataset[train_dataset.columns[1:]], train_dataset[train_dataset.columns[0]], test_dataset[test_dataset.columns[1:]], test_dataset[test_dataset.columns[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "R1FOBHIe_76o"
      },
      "outputs": [],
      "source": [
        "x_train, y_train, x_test, y_test = train_test_split(pd_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1aUQ2K-BGZ5"
      },
      "source": [
        "### 3. Data examination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUXBgnYdgH7T"
      },
      "source": [
        "The task would be to examine the dataset. Check:\n",
        "\n",
        "1. Is it a classification of regression task?\n",
        "2. How many data samples do we have?\n",
        "3. How many features do we have?  \n",
        "4. What data types do we have in our dataset?\n",
        "5. Are there any missing values?\n",
        "6. How many labels do we have? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "0pKswr1YhMsS",
        "outputId": "e1b1ce79-456e-4745-ea25-86241dd4c6ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    handicapped-infants water-project-cost-sharing  \\\n",
              "0                     n                          y   \n",
              "1                     n                          y   \n",
              "2                     ?                          y   \n",
              "3                     n                          y   \n",
              "4                     y                          y   \n",
              "..                  ...                        ...   \n",
              "343                   n                          n   \n",
              "344                   n                          n   \n",
              "345                   n                          ?   \n",
              "346                   n                          n   \n",
              "347                   n                          y   \n",
              "\n",
              "    adoption-of-the-budget-resolution physician-fee-freeze el-salvador-aid  \\\n",
              "0                                   n                    y               y   \n",
              "1                                   n                    y               y   \n",
              "2                                   y                    ?               y   \n",
              "3                                   y                    n               ?   \n",
              "4                                   y                    n               y   \n",
              "..                                ...                  ...             ...   \n",
              "343                                 y                    y               y   \n",
              "344                                 y                    n               n   \n",
              "345                                 n                    y               y   \n",
              "346                                 n                    y               y   \n",
              "347                                 n                    y               y   \n",
              "\n",
              "    religious-groups-in-schools anti-satellite-test-ban  \\\n",
              "0                             y                       n   \n",
              "1                             y                       n   \n",
              "2                             y                       n   \n",
              "3                             y                       n   \n",
              "4                             y                       n   \n",
              "..                          ...                     ...   \n",
              "343                           y                       n   \n",
              "344                           n                       y   \n",
              "345                           y                       n   \n",
              "346                           y                       ?   \n",
              "347                           y                       n   \n",
              "\n",
              "    aid-to-nicaraguan-contras mx-missile immigration  \\\n",
              "0                           n          n           y   \n",
              "1                           n          n           n   \n",
              "2                           n          n           n   \n",
              "3                           n          n           n   \n",
              "4                           n          n           n   \n",
              "..                        ...        ...         ...   \n",
              "343                         n          y           y   \n",
              "344                         y          y           y   \n",
              "345                         n          n           n   \n",
              "346                         ?          ?           ?   \n",
              "347                         n          n           y   \n",
              "\n",
              "    synfuels-corporation-cutback education-spending superfund-right-to-sue  \\\n",
              "0                              ?                  y                      y   \n",
              "1                              n                  y                      y   \n",
              "2                              y                  n                      y   \n",
              "3                              y                  n                      y   \n",
              "4                              y                  ?                      y   \n",
              "..                           ...                ...                    ...   \n",
              "343                            n                  y                      y   \n",
              "344                            n                  n                      n   \n",
              "345                            y                  y                      y   \n",
              "346                            n                  y                      y   \n",
              "347                            n                  y                      y   \n",
              "\n",
              "    crime duty-free-exports export-administration-act-south-africa  \n",
              "0       y                 n                                      y  \n",
              "1       y                 n                                      ?  \n",
              "2       y                 n                                      n  \n",
              "3       n                 n                                      y  \n",
              "4       y                 y                                      y  \n",
              "..    ...               ...                                    ...  \n",
              "343     y                 n                                      y  \n",
              "344     n                 n                                      y  \n",
              "345     y                 n                                      y  \n",
              "346     y                 n                                      y  \n",
              "347     y                 ?                                      n  \n",
              "\n",
              "[348 rows x 16 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b5f9faa9-3d0f-4572-86a1-00dfcfb25dc4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handicapped-infants</th>\n",
              "      <th>water-project-cost-sharing</th>\n",
              "      <th>adoption-of-the-budget-resolution</th>\n",
              "      <th>physician-fee-freeze</th>\n",
              "      <th>el-salvador-aid</th>\n",
              "      <th>religious-groups-in-schools</th>\n",
              "      <th>anti-satellite-test-ban</th>\n",
              "      <th>aid-to-nicaraguan-contras</th>\n",
              "      <th>mx-missile</th>\n",
              "      <th>immigration</th>\n",
              "      <th>synfuels-corporation-cutback</th>\n",
              "      <th>education-spending</th>\n",
              "      <th>superfund-right-to-sue</th>\n",
              "      <th>crime</th>\n",
              "      <th>duty-free-exports</th>\n",
              "      <th>export-administration-act-south-africa</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>n</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>n</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>y</td>\n",
              "      <td>?</td>\n",
              "      <td>n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>348 rows  16 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b5f9faa9-3d0f-4572-86a1-00dfcfb25dc4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b5f9faa9-3d0f-4572-86a1-00dfcfb25dc4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b5f9faa9-3d0f-4572-86a1-00dfcfb25dc4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "x_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTxf4gaqrLge"
      },
      "source": [
        "### 4. Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcJ41-OtrOah"
      },
      "source": [
        "When you preprocess your traing data, do not forget that you need to apply the same preprocessing also for your test set. For example: If you decide to delete some columns in your train set, you have to delete the same columns in your test set. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWPwLG1EWiQ"
      },
      "source": [
        "Possible preprocessing steps (try several and see the influence of your preprocessing on your results)\n",
        " - Replace missing values with any data imputation technique ( for example, the most occurring value in the column), then perform one-hot encoding or label encoding of your data\n",
        " - Consider the missing value to be the third category 'unknown' and then perform one-hot encoding or label encoding\n",
        "\n",
        "The target value also has to be encoded. This can be done by one-hot encoding or label encoding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = pd.get_dummies(x_train)\n",
        "x"
      ],
      "metadata": {
        "id": "d2ridfTFXInN",
        "outputId": "e5ea6266-9f83-45a7-dfae-b062aeec25b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     handicapped-infants  water-project-cost-sharing_?  \\\n",
              "0                    0.0                             0   \n",
              "1                    0.0                             0   \n",
              "2                    NaN                             0   \n",
              "3                    0.0                             0   \n",
              "4                    1.0                             0   \n",
              "..                   ...                           ...   \n",
              "343                  0.0                             0   \n",
              "344                  0.0                             0   \n",
              "345                  0.0                             1   \n",
              "346                  0.0                             0   \n",
              "347                  0.0                             0   \n",
              "\n",
              "     water-project-cost-sharing_n  water-project-cost-sharing_y  \\\n",
              "0                               0                             1   \n",
              "1                               0                             1   \n",
              "2                               0                             1   \n",
              "3                               0                             1   \n",
              "4                               0                             1   \n",
              "..                            ...                           ...   \n",
              "343                             1                             0   \n",
              "344                             1                             0   \n",
              "345                             0                             0   \n",
              "346                             1                             0   \n",
              "347                             0                             1   \n",
              "\n",
              "     adoption-of-the-budget-resolution_?  adoption-of-the-budget-resolution_n  \\\n",
              "0                                      0                                    1   \n",
              "1                                      0                                    1   \n",
              "2                                      0                                    0   \n",
              "3                                      0                                    0   \n",
              "4                                      0                                    0   \n",
              "..                                   ...                                  ...   \n",
              "343                                    0                                    0   \n",
              "344                                    0                                    0   \n",
              "345                                    0                                    1   \n",
              "346                                    0                                    1   \n",
              "347                                    0                                    1   \n",
              "\n",
              "     adoption-of-the-budget-resolution_y  physician-fee-freeze_?  \\\n",
              "0                                      0                       0   \n",
              "1                                      0                       0   \n",
              "2                                      1                       1   \n",
              "3                                      1                       0   \n",
              "4                                      1                       0   \n",
              "..                                   ...                     ...   \n",
              "343                                    1                       0   \n",
              "344                                    1                       0   \n",
              "345                                    0                       0   \n",
              "346                                    0                       0   \n",
              "347                                    0                       0   \n",
              "\n",
              "     physician-fee-freeze_n  physician-fee-freeze_y  ...  \\\n",
              "0                         0                       1  ...   \n",
              "1                         0                       1  ...   \n",
              "2                         0                       0  ...   \n",
              "3                         1                       0  ...   \n",
              "4                         1                       0  ...   \n",
              "..                      ...                     ...  ...   \n",
              "343                       0                       1  ...   \n",
              "344                       1                       0  ...   \n",
              "345                       0                       1  ...   \n",
              "346                       0                       1  ...   \n",
              "347                       0                       1  ...   \n",
              "\n",
              "     superfund-right-to-sue_y  crime_?  crime_n  crime_y  duty-free-exports_?  \\\n",
              "0                           1        0        0        1                    0   \n",
              "1                           1        0        0        1                    0   \n",
              "2                           1        0        0        1                    0   \n",
              "3                           1        0        1        0                    0   \n",
              "4                           1        0        0        1                    0   \n",
              "..                        ...      ...      ...      ...                  ...   \n",
              "343                         1        0        0        1                    0   \n",
              "344                         0        0        1        0                    0   \n",
              "345                         1        0        0        1                    0   \n",
              "346                         1        0        0        1                    0   \n",
              "347                         1        0        0        1                    1   \n",
              "\n",
              "     duty-free-exports_n  duty-free-exports_y  \\\n",
              "0                      1                    0   \n",
              "1                      1                    0   \n",
              "2                      1                    0   \n",
              "3                      1                    0   \n",
              "4                      0                    1   \n",
              "..                   ...                  ...   \n",
              "343                    1                    0   \n",
              "344                    1                    0   \n",
              "345                    1                    0   \n",
              "346                    1                    0   \n",
              "347                    0                    0   \n",
              "\n",
              "     export-administration-act-south-africa_?  \\\n",
              "0                                           0   \n",
              "1                                           1   \n",
              "2                                           0   \n",
              "3                                           0   \n",
              "4                                           0   \n",
              "..                                        ...   \n",
              "343                                         0   \n",
              "344                                         0   \n",
              "345                                         0   \n",
              "346                                         0   \n",
              "347                                         0   \n",
              "\n",
              "     export-administration-act-south-africa_n  \\\n",
              "0                                           0   \n",
              "1                                           0   \n",
              "2                                           1   \n",
              "3                                           0   \n",
              "4                                           0   \n",
              "..                                        ...   \n",
              "343                                         0   \n",
              "344                                         0   \n",
              "345                                         0   \n",
              "346                                         0   \n",
              "347                                         1   \n",
              "\n",
              "     export-administration-act-south-africa_y  \n",
              "0                                           1  \n",
              "1                                           0  \n",
              "2                                           0  \n",
              "3                                           1  \n",
              "4                                           1  \n",
              "..                                        ...  \n",
              "343                                         1  \n",
              "344                                         1  \n",
              "345                                         1  \n",
              "346                                         1  \n",
              "347                                         0  \n",
              "\n",
              "[348 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41543586-4d9a-40d8-a3dc-a80e7cd349db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handicapped-infants</th>\n",
              "      <th>water-project-cost-sharing_?</th>\n",
              "      <th>water-project-cost-sharing_n</th>\n",
              "      <th>water-project-cost-sharing_y</th>\n",
              "      <th>adoption-of-the-budget-resolution_?</th>\n",
              "      <th>adoption-of-the-budget-resolution_n</th>\n",
              "      <th>adoption-of-the-budget-resolution_y</th>\n",
              "      <th>physician-fee-freeze_?</th>\n",
              "      <th>physician-fee-freeze_n</th>\n",
              "      <th>physician-fee-freeze_y</th>\n",
              "      <th>...</th>\n",
              "      <th>superfund-right-to-sue_y</th>\n",
              "      <th>crime_?</th>\n",
              "      <th>crime_n</th>\n",
              "      <th>crime_y</th>\n",
              "      <th>duty-free-exports_?</th>\n",
              "      <th>duty-free-exports_n</th>\n",
              "      <th>duty-free-exports_y</th>\n",
              "      <th>export-administration-act-south-africa_?</th>\n",
              "      <th>export-administration-act-south-africa_n</th>\n",
              "      <th>export-administration-act-south-africa_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>348 rows  46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41543586-4d9a-40d8-a3dc-a80e7cd349db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-41543586-4d9a-40d8-a3dc-a80e7cd349db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-41543586-4d9a-40d8-a3dc-a80e7cd349db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "DvulEffMsfbs"
      },
      "outputs": [],
      "source": [
        "#WRITE YOUR CODE HERE\n",
        "y_train = y_train.replace('republican', 1)\n",
        "y = y_train.replace('democrat', 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdmHivmkuGZy"
      },
      "source": [
        "### 5. Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4FBQOiJGGDa"
      },
      "source": [
        "1. Create your model using alteast one hidden layer. \n",
        "\n",
        "*hint: do not create too complex models, this is a very simple task, so it would be enought to use just few neurons in the hidden layers*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.columns)\n",
        "print(len(x.columns))"
      ],
      "metadata": {
        "id": "zQRaWdZYZnWD",
        "outputId": "c2cec289-65cc-4fbe-91bf-ab88109985e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['handicapped-infants', 'water-project-cost-sharing_?',\n",
            "       'water-project-cost-sharing_n', 'water-project-cost-sharing_y',\n",
            "       'adoption-of-the-budget-resolution_?',\n",
            "       'adoption-of-the-budget-resolution_n',\n",
            "       'adoption-of-the-budget-resolution_y', 'physician-fee-freeze_?',\n",
            "       'physician-fee-freeze_n', 'physician-fee-freeze_y', 'el-salvador-aid_?',\n",
            "       'el-salvador-aid_n', 'el-salvador-aid_y',\n",
            "       'religious-groups-in-schools_?', 'religious-groups-in-schools_n',\n",
            "       'religious-groups-in-schools_y', 'anti-satellite-test-ban_?',\n",
            "       'anti-satellite-test-ban_n', 'anti-satellite-test-ban_y',\n",
            "       'aid-to-nicaraguan-contras_?', 'aid-to-nicaraguan-contras_n',\n",
            "       'aid-to-nicaraguan-contras_y', 'mx-missile_?', 'mx-missile_n',\n",
            "       'mx-missile_y', 'immigration_?', 'immigration_n', 'immigration_y',\n",
            "       'synfuels-corporation-cutback_?', 'synfuels-corporation-cutback_n',\n",
            "       'synfuels-corporation-cutback_y', 'education-spending_?',\n",
            "       'education-spending_n', 'education-spending_y',\n",
            "       'superfund-right-to-sue_?', 'superfund-right-to-sue_n',\n",
            "       'superfund-right-to-sue_y', 'crime_?', 'crime_n', 'crime_y',\n",
            "       'duty-free-exports_?', 'duty-free-exports_n', 'duty-free-exports_y',\n",
            "       'export-administration-act-south-africa_?',\n",
            "       'export-administration-act-south-africa_n',\n",
            "       'export-administration-act-south-africa_y'],\n",
            "      dtype='object')\n",
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "tUGDXUEFs093"
      },
      "outputs": [],
      "source": [
        "# WRITE YOU CODE HERE\n",
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=len(x.columns), activation='sigmoid'))\n",
        "model.add(Dense(4, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87ZBo4g5Klno"
      },
      "source": [
        "2. Check what *model.summary()* does"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "s2lwjf4Yu1Wh",
        "outputId": "03edf7e6-2b0f-41a4-d247-43d82f470ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 4)                 188       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 4)                 20        \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213\n",
            "Trainable params: 213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# WRITE YOU CODE HERE\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugHf36DoKrHT"
      },
      "source": [
        "3. Compile the model, choose a suitable loss function, choose gradient to descend optimizer and specify the learning rate, and choose accuracy as our metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "ejSrDLDDu1w4"
      },
      "outputs": [],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.5)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hc9SWvcMRzX"
      },
      "source": [
        "4. Train the model. Specify the number of epochs and batch size. Now is the time to create a validation dataset. Set 20% of dataset to be a validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "6UjQuXXCMEu2",
        "outputId": "be88d1bb-ec21-4f58-98f4-3da86a50b90e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "32/32 [==============================] - 1s 9ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 2/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 3/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 4/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 5/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 6/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 7/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 8/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 9/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 10/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 11/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 12/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 13/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 14/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 15/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 16/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 17/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 18/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 19/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 20/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 21/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 22/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 23/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 24/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 25/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 26/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 27/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 28/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 29/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 30/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 31/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 32/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 33/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 34/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 35/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 36/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 37/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 38/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 39/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 40/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 41/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 42/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 43/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 44/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 45/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 46/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 47/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 48/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 49/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 50/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 51/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 52/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 53/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 54/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 55/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 56/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 57/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 58/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 59/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 60/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 61/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 62/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 63/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 64/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 65/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 66/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 67/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 68/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 69/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 70/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 71/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 72/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 73/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 74/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 75/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 76/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 77/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 78/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 79/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 80/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 81/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 82/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 83/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 84/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 85/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 86/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 87/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 88/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 89/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 90/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 91/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 92/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 93/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 94/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 95/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 96/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 97/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 98/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 99/1000\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 100/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 101/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 102/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 103/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 104/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 105/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 106/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 107/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 108/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 109/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 110/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 111/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 112/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 113/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 114/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 115/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 116/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 117/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 118/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 119/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 120/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 121/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 122/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 123/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 124/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 125/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 126/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 127/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 128/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 129/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 130/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 131/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 132/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 133/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 134/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 135/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 136/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 137/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 138/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 139/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 140/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 141/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 142/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 143/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 144/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 145/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 146/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 147/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 148/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 149/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 150/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 151/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 152/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 153/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 154/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 155/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 156/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 157/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 158/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 159/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 160/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 161/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 162/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 163/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 164/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 165/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 166/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 167/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 168/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 169/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 170/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 171/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 172/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 173/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 174/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 175/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 176/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 177/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 178/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 179/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 180/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 181/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 182/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 183/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 184/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 185/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 186/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 187/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 188/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 189/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 190/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 191/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 192/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 193/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 194/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 195/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 196/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 197/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 198/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 199/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 200/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 201/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 202/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 203/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 204/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 205/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 206/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 207/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 208/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 209/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 210/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 211/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 212/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 213/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 214/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 215/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 216/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 217/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 218/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 219/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 220/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 221/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 222/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 223/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 224/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 225/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 226/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 227/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 228/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 229/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 230/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 231/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 232/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 233/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 234/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 235/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 236/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 237/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 238/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 239/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 240/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 241/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 242/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 243/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 244/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 245/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 246/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 247/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 248/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 249/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 250/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 251/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 252/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 253/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 254/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 255/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 256/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 257/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 258/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 259/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 260/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 261/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 262/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 263/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 264/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 265/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 266/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 267/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 268/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 269/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 270/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 271/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 272/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 273/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 274/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 275/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 276/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 277/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 278/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 279/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 280/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 281/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 282/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 283/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 284/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 285/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 286/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 287/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 288/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 289/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 290/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 291/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 292/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 293/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 294/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 295/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 296/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 297/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 298/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 299/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 300/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 301/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 302/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 303/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 304/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 305/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 306/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 307/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 308/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 309/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 310/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 311/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 312/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 313/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 314/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 315/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 316/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 317/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 318/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 319/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 320/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 321/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 322/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 323/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 324/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 325/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 326/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 327/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 328/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 329/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 330/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 331/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 332/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 333/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 334/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 335/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 336/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 337/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 338/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 339/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 340/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 341/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 342/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 343/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 344/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 345/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 346/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 347/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 348/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 349/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 350/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 351/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 352/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 353/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 354/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 355/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 356/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 357/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 358/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 359/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 360/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 361/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 362/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 363/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 364/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 365/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 366/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 367/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 368/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 369/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 370/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 371/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 372/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 373/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 374/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 375/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 376/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 377/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 378/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 379/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 380/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 381/1000\n",
            "32/32 [==============================] - 0s 8ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 382/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 383/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 384/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 385/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 386/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 387/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 388/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 389/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 390/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 391/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 392/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 393/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 394/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 395/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 396/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 397/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 398/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 399/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 400/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 401/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 402/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 403/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 404/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 405/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 406/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 407/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 408/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 409/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 410/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 411/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 412/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 413/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 414/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 415/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 416/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 417/1000\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 418/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 419/1000\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 420/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 421/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 422/1000\n",
            "32/32 [==============================] - 0s 10ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 423/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 424/1000\n",
            "32/32 [==============================] - 0s 9ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 425/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 426/1000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 427/1000\n",
            "32/32 [==============================] - 0s 11ms/step - loss: nan - accuracy: 0.6326 - val_loss: nan - val_accuracy: 0.4857\n",
            "Epoch 428/1000\n",
            "15/32 [=============>................] - ETA: 0s - loss: nan - accuracy: 0.6333"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-708f8d7f4f8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#WRITE YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1654\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[1;32m    475\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1094\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_finalize_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mio_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline_break\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/io_utils.py\u001b[0m in \u001b[0;36mprint_msg\u001b[0;34m(message, line_break)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m                 \u001b[0;31m# and give a timeout to avoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                     \u001b[0;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                     \u001b[0;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#WRITE YOUR CODE HERE\n",
        "history = model.fit(x, y, epochs=500, batch_size=10, verbose=1, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQMbJKL8KHeL"
      },
      "source": [
        "### 7. Model Evaluation \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzqLTyNOMtkG"
      },
      "source": [
        "1. First, apply the same preprocessing you did to train set to test set also"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "fwPbro7dKVZJ",
        "outputId": "c9b0b49d-90bd-4736-e801-91250aa4d6c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    handicapped-infants_?  handicapped-infants_n  handicapped-infants_y  \\\n",
              "0                       0                      1                      0   \n",
              "1                       0                      1                      0   \n",
              "2                       0                      0                      1   \n",
              "3                       0                      0                      1   \n",
              "4                       0                      0                      1   \n",
              "..                    ...                    ...                    ...   \n",
              "82                      0                      1                      0   \n",
              "83                      0                      0                      1   \n",
              "84                      0                      1                      0   \n",
              "85                      0                      0                      1   \n",
              "86                      0                      1                      0   \n",
              "\n",
              "    water-project-cost-sharing_?  water-project-cost-sharing_n  \\\n",
              "0                              0                             0   \n",
              "1                              0                             0   \n",
              "2                              1                             0   \n",
              "3                              0                             1   \n",
              "4                              0                             0   \n",
              "..                           ...                           ...   \n",
              "82                             0                             1   \n",
              "83                             0                             1   \n",
              "84                             0                             0   \n",
              "85                             0                             0   \n",
              "86                             0                             1   \n",
              "\n",
              "    water-project-cost-sharing_y  adoption-of-the-budget-resolution_?  \\\n",
              "0                              1                                    0   \n",
              "1                              1                                    0   \n",
              "2                              0                                    0   \n",
              "3                              0                                    0   \n",
              "4                              1                                    0   \n",
              "..                           ...                                  ...   \n",
              "82                             0                                    0   \n",
              "83                             0                                    0   \n",
              "84                             1                                    0   \n",
              "85                             1                                    0   \n",
              "86                             0                                    0   \n",
              "\n",
              "    adoption-of-the-budget-resolution_n  adoption-of-the-budget-resolution_y  \\\n",
              "0                                     1                                    0   \n",
              "1                                     1                                    0   \n",
              "2                                     1                                    0   \n",
              "3                                     0                                    1   \n",
              "4                                     0                                    1   \n",
              "..                                  ...                                  ...   \n",
              "82                                    1                                    0   \n",
              "83                                    0                                    1   \n",
              "84                                    0                                    1   \n",
              "85                                    0                                    1   \n",
              "86                                    0                                    1   \n",
              "\n",
              "    physician-fee-freeze_?  ...  superfund-right-to-sue_y  crime_?  crime_n  \\\n",
              "0                        0  ...                         1        0        0   \n",
              "1                        0  ...                         1        1        0   \n",
              "2                        0  ...                         0        0        0   \n",
              "3                        0  ...                         1        0        1   \n",
              "4                        0  ...                         0        0        1   \n",
              "..                     ...  ...                       ...      ...      ...   \n",
              "82                       0  ...                         1        0        0   \n",
              "83                       0  ...                         0        0        1   \n",
              "84                       0  ...                         0        0        1   \n",
              "85                       0  ...                         1        0        1   \n",
              "86                       0  ...                         0        0        1   \n",
              "\n",
              "    crime_y  duty-free-exports_?  duty-free-exports_n  duty-free-exports_y  \\\n",
              "0         1                    0                    1                    0   \n",
              "1         0                    0                    1                    0   \n",
              "2         1                    0                    1                    0   \n",
              "3         0                    0                    0                    1   \n",
              "4         0                    0                    1                    0   \n",
              "..      ...                  ...                  ...                  ...   \n",
              "82        1                    0                    1                    0   \n",
              "83        0                    0                    1                    0   \n",
              "84        0                    0                    1                    0   \n",
              "85        0                    0                    1                    0   \n",
              "86        0                    0                    0                    1   \n",
              "\n",
              "    export-administration-act-south-africa_?  \\\n",
              "0                                          0   \n",
              "1                                          1   \n",
              "2                                          0   \n",
              "3                                          0   \n",
              "4                                          1   \n",
              "..                                       ...   \n",
              "82                                         0   \n",
              "83                                         0   \n",
              "84                                         0   \n",
              "85                                         0   \n",
              "86                                         0   \n",
              "\n",
              "    export-administration-act-south-africa_n  \\\n",
              "0                                          0   \n",
              "1                                          0   \n",
              "2                                          0   \n",
              "3                                          0   \n",
              "4                                          0   \n",
              "..                                       ...   \n",
              "82                                         0   \n",
              "83                                         0   \n",
              "84                                         0   \n",
              "85                                         0   \n",
              "86                                         0   \n",
              "\n",
              "    export-administration-act-south-africa_y  \n",
              "0                                          1  \n",
              "1                                          0  \n",
              "2                                          1  \n",
              "3                                          1  \n",
              "4                                          0  \n",
              "..                                       ...  \n",
              "82                                         1  \n",
              "83                                         1  \n",
              "84                                         1  \n",
              "85                                         1  \n",
              "86                                         1  \n",
              "\n",
              "[87 rows x 46 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f53b0095-b9e1-43f6-a958-00643fa99a24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>handicapped-infants_?</th>\n",
              "      <th>handicapped-infants_n</th>\n",
              "      <th>handicapped-infants_y</th>\n",
              "      <th>water-project-cost-sharing_?</th>\n",
              "      <th>water-project-cost-sharing_n</th>\n",
              "      <th>water-project-cost-sharing_y</th>\n",
              "      <th>adoption-of-the-budget-resolution_?</th>\n",
              "      <th>adoption-of-the-budget-resolution_n</th>\n",
              "      <th>adoption-of-the-budget-resolution_y</th>\n",
              "      <th>physician-fee-freeze_?</th>\n",
              "      <th>...</th>\n",
              "      <th>superfund-right-to-sue_y</th>\n",
              "      <th>crime_?</th>\n",
              "      <th>crime_n</th>\n",
              "      <th>crime_y</th>\n",
              "      <th>duty-free-exports_?</th>\n",
              "      <th>duty-free-exports_n</th>\n",
              "      <th>duty-free-exports_y</th>\n",
              "      <th>export-administration-act-south-africa_?</th>\n",
              "      <th>export-administration-act-south-africa_n</th>\n",
              "      <th>export-administration-act-south-africa_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>87 rows  46 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f53b0095-b9e1-43f6-a958-00643fa99a24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f53b0095-b9e1-43f6-a958-00643fa99a24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f53b0095-b9e1-43f6-a958-00643fa99a24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "x_test_precproc = pd.get_dummies(x_test)\n",
        "x_test_precproc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_p = y_test.replace('republican', 1)\n",
        "y_test_preproc = y_test_p.replace('democrat', 0)"
      ],
      "metadata": {
        "id": "_9lbiq2yc-v5"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rE34DAnkM7jM"
      },
      "source": [
        "2. Evaluate the model, print final accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "kmmp_9vPwaBJ",
        "outputId": "bbf461a8-36c8-43b3-8f7d-a5edc39e9189",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 59.77\n"
          ]
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "loss, accuracy = model.evaluate(x_test_precproc, y_test_preproc, verbose=0)\n",
        "print('Accuracy: {:.2f}'.format(accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOTKHtFsNEZV"
      },
      "source": [
        "3. Plot loss and validation loss depending on the training epochs into one graph. In another graph, plot accuracy and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for id_x, data_sample in enumerate(x_test_precproc):\n",
        "  print(data_sample)\n",
        "  prediction = model.predict([data_sample])\n",
        "  print(f\"Data sample is {data_sample}, prediction from model {prediction}, ground_truth {y[id_x]}\")"
      ],
      "metadata": {
        "id": "rha8Y-lgd2R-",
        "outputId": "c355a62a-977f-4bb4-85e9-8a30543d0858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-e31053097daf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test_precproc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Data sample is {data_sample}, prediction from model {prediction}, ground_truth {y[id_x]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "1SAkMeD4yA5x",
        "outputId": "4802ba28-172e-4e90-e9d9-d5eddd7646da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "metadata": {},
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# WRITE YOUR CODE HERE\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('n epochs')\n",
        "plt.ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cU-4VJsh0Z_1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}